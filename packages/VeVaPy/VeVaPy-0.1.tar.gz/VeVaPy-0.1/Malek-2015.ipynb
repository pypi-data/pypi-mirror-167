{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Malek et al. (2015) Model Code <a name=\"top\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [Instructions](#instructions)\n",
    "    1. [Parameter Optimization Against TSST Data Sets](#TSSTInstructions)\n",
    "    2. [Parameter Optimization Against Basal Data Sets](#basalInstructions)\n",
    "    3. [Running Without Parameter Optimization](#noOptInstructions)\n",
    "2. [Imports](#imports)\n",
    "3. [Parameters and Initial Conditions](#params)\n",
    "4. [Put Raw Data into Arrays](#rawdata)\n",
    "    1. [Plot Data Sets](#plotdata)\n",
    "5. [Model Function--Includes ODE Solver](#modelfunction)\n",
    "6. [Functions to Determine Delayed ACTH and Cortisol Values](#delays)\n",
    "7. [Delay Functions for Larger Time Steps](#largerdelays)\n",
    "8. [Cost Function Definition](#cost)\n",
    "9. [Run the Optimization](#run)\n",
    "10. [Save Output to File](#saveoutput)\n",
    "11. [Compute Means and Std Devations of Parameters and Output as Table](#paramtable)\n",
    "12. [Plots](#plots)\n",
    "13. [No Optimization Run](#no-opt)\n",
    "14. [Run Optimizations for Multiple Patients](#runMultiple)\n",
    "15. [Dependencies](#dependencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions <a name=\"instructions\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Optimization Against TSST Data Sets <a name=\"TSSTInstructions\" />\n",
    "\n",
    "**Note:** To quickly run a cell (or a selection of cells), use the shortcut Shift+Enter (or you can also use the button labeled \"Run\" in the toolbar at the top).\n",
    "\n",
    "To run simulations with parameter optimization against TSST data, there is no need to change any cells until the heading **Run the Optimization**. Simply run all cells up to the cell below that heading.\n",
    "\n",
    "In order to set which data set to optimize parameters against, look for the following line of code:\n",
    "    \n",
    "    data_to_match = [nelson.ACTH[:,0], nelson.ACTH[:,1], nelson.cortisol[:,0], nelson.cortisol[:,1]]\n",
    "\n",
    "In order to run against a patient from the TSST data sets, simply change the list entries to reflect the patient number and subject group. The subject groups are:\n",
    "\n",
    "- nelson.melancholicACTH & nelson.melancholicCortisol (15 patients)\n",
    "- nelson.atypicalACTH & nelson.atypicalCortisol (14 patients)\n",
    "- nelson.neitherACTH & nelson.neitherCortisol (14 patients)\n",
    "- nelson.healthyACTH & nelson.healthyCortisol (15 patients)\n",
    "\n",
    "You could also run against the mean of all patients cortisol and ACTH concentration values by using `nelson.ACTH[:,1]` and `nelson.cortisol[:,1]`. Or you can run against the mean of any subgroup using `nelson.<subgroup name>Cortisol_mean[:,1]` and `nelson.<subgroup name>ACTH_mean[:,1]` (for instance `nelson.melancholicCortisol_mean[:,1]` & `nelson.melancholicACTH_mean[:,1]`). \n",
    "\n",
    "Note that the first column in each data set is the time steps, so indexing with `[:,0]` is referring to the time. These are the values we need to set as the first (ACTH time steps) and third (cortisol time steps) indices of the `data_to_match` list.\n",
    "\n",
    "The following are several examples of lists you could use for parameter optimization with explanations:\n",
    "\n",
    "- `nelson.melancholicACTH[:,0], nelson.melancholicACTH[:,1], nelson.melancholicCortisol[:,0], nelson.melancholicCortisol[:,1]`\n",
    "    - The 1st patient in the Melancholic subgroup\n",
    "- `nelson.atypicalACTH[:,0], nelson.atypicalACTH[:,14], nelson.atypicalCortisol[:,0], nelson.atypicalCortisol[:,14]`\n",
    "    - The 14th patient in the Atypical subgroup\n",
    "- `nelson.healthyACTH[:,0], nelson.healthyACTH[:,2], nelson.healthyCortisol[:,0], nelson.healthyCortisol[:,2]`\n",
    "    - The 2nd patient in the Healthy Control group\n",
    "- `nelson.ACTH[:,0], nelson.ACTH[:,1], nelson.cortisol[:,0], nelson.cortisol[:,1]`\n",
    "    - The mean data set for all patients (depressed and control)\n",
    "- `nelson.healthyACTH_mean[:,0], nelson.healthyACTH_mean[:,1], nelson.healthyCortisol_mean[:,0], nelson.healthyCortisol_mean[:,1]`\n",
    "    - The mean of all control patients\n",
    "    \n",
    "It is unlikely that you will need to optimize any initial conditions (ICs), because the only ICs other than ACTH and cortisol are inflammatory cytokines. However, if necessary, this can be modified in the function `cost_fun(params)`. In the example below, we use the first three optimized parameters in the list returned by the optimization algorithm to set the ICs we want to optimize (LPS, TNF-alpha and IL-6 in this example):\n",
    "\n",
    "    y0 = [params[0], params[1], params[2], y0[1], y0[2]]\n",
    "\n",
    "We then need to pass only the remaining parameters in the list to the model, along with the updated ICs in y0:\n",
    "\n",
    "    simData = model(params[3:], y0)\n",
    "    \n",
    "If you want to not optimize any ICs, you would simply leave the cost function as it is currently written.\n",
    "\n",
    "At this point, you are ready to run the optimization, so simply run the cells up to the heading **Save Output to File**. This may take some time, so while it is running you can move on to the next steps (if you run a cell while another is processing, it will add it to a queue).\n",
    "\n",
    "**Note:** You also have the option of using a cost function based on the maximum distance between simulation and real-world data. Simply change SSE_cost to MAX_cost, the instructions for function arguments remain the same.\n",
    "\n",
    "The cell directly under the heading **Save Output to File** can be changed so that the root filename matches the simulations being run. This root will be used to save all of the various data and figures generated. The current naming scheme would save the files for 5 iterations of parameter optimization against the mean data set from the Nelson with ICs for CRH and GR optimized as:\n",
    "\n",
    "    filename_root = \"malekModel_output/nelson-patientMean-5-iterations-ICOpt\"\n",
    "\n",
    "This saves the files in a subfolder specific to this model, which helps keep files organized when running multiple models.\n",
    "\n",
    "The next few cells create an Excel file containing all of the concentration data and optimized parameter values, and text files containing the initial conditions, parameter bounds and parameter means +- standard deviation across the 5 iterations.\n",
    "\n",
    "The final step after saving the outputs is to plot the simulations against the real-world data. The cell under the heading **Plots** creates an instance of the Visualizer object from the VeVaPy module called visualize. This will start a dialog which asks for several inputs to generate figures as desired.\n",
    "\n",
    "After initialization of the object, run its method `make_graphs()`, and it will generate figures using the data you have specified. There are a number of arguments that can be optionally specified for this method, and you can see more details by running the command:\n",
    "\n",
    "    help(Visualizer)\n",
    "\n",
    "    \n",
    "## Parameter Optimization Against Basal Data Sets <a name=\"basalInstructions\" />\n",
    "\n",
    "Since these data sets have data points over a 24-hour period (1440 minutes), rather than 140.5 minutes, you will need to change the time interval over which the ODE solver integrates. To do this, go to the cell directly above the heading **Put Raw Data Into Arrays** and uncomment (delete the # at the start of the line) the lines:\n",
    "\n",
    "    t_start = -0.5\n",
    "    t_end = 1455.5\n",
    "    t_step = 0.5\n",
    "\n",
    "You'll need to comment out the other definitons for these variables (place a # at the start of the line).\n",
    "\n",
    "The reason you add the extra 15 minutes is that you need to make sure that when you interpolate between your simulated data points the line covers every real-world data point so that you don't cause issues when computing the cost function (and the last data point for the Golier cortisol concentration data sets is at 1455 minutes).\n",
    "\n",
    "After making this change, you need to again change the `data_to_match` list so that you are matching the basal data set in which you are interested.\n",
    "\n",
    "First, choose which data set you wish to match. Here are the options:\n",
    "\n",
    "- yehuda.controlCortisol\n",
    "- yehuda.PTSDCortisol\n",
    "- yehuda.depressedCortisol\n",
    "- carroll.controlCortisol & carroll.controlACTH\n",
    "- carroll.LCDepressedCortisol & carroll.LCDepressedACTH (LC = Low Cortisol)\n",
    "- carroll.HCDepressedCortisol & carroll.HCDepressedACTH (HC = High Cortisol)\n",
    "- golier.PTSDCortisol & golierPTSDACTH\n",
    "- golier.nonPTSDTraumaExposedCortisol & golier.nonPTSDTraumaExposedACTH\n",
    "- golier.nonPTSDNonExposedCortisol & golier.nonPTSDNonExposedACTH\n",
    "- bremner.abusedPTSDCortisol\n",
    "- bremner.nonAbusedPTSDCortisol\n",
    "- bremner.nonAbusedNonPTSDCortisol\n",
    "\n",
    "**Note:** To see what any of these data sets looks like, click on the **Plot Basal Data Sets** heading in the Table of Contents.\n",
    "\n",
    "**Note Also:** These data sets all come in smoothed versions (each data point is set to the average of the nearest 5 points of the unsmoothed data). Also, the data sets by Carroll, Golier and Bremner also come in rearranged (or smoothed & rearranged) versions to match the starting time of the Yehuda data (10AM). To use any of these versions, simply append one of the following tags to the end of the data set name (before the indices): `_smooth`, `_rearr`, or `_rearr_smooth`.\n",
    "\n",
    "First, I will cover what to do with data sets that contain both ACTH and cortisol values, and then afterwards I will cover using the Yehuda and Bremner data sets (which have only cortisol concentration data). Just as with the Nelson data, in all of these data sets the first column is the time step values. This means that if you take any of these arrays and index it with `[:,0]`, you are referring to the time steps. These are the values we need to use as the first (ACTH time steps) and third (cortisol time steps) indices in the `data_to_match` list.\n",
    "\n",
    "Then for the second and fourth indices, you index the same data sets with `[:,1]` to mean the second column (which contains the mean concentration values for each patient group).\n",
    "\n",
    "Here are a couple of examples showing lists you can use for optimization:\n",
    "\n",
    "- `carroll.controlACTH_smooth[:,0], carroll.controlACTH_smooth[:,1], carroll.controlCortisol_smooth[:,0], carroll.controlCortisol_smooth[:,1]`\n",
    "    - The smoothed Control group mean for the Carroll data set\n",
    "- `golier.nonPTSDTraumaExposedACTH[:,0], golier.nonPTSDTraumaExposedACTH[:,1], golier.nonPTSDTraumaExposedCortisol[:,0], golier.nonPTSDTraumaExposedCortisol[:,1]`\n",
    "    - The Trauma-Exposed Control group mean for the Golier data set\n",
    "    \n",
    "In order to run simulations against data sets that do not include ACTH concentration data, you will need to change the name of the cost function to `optimize.SSE_cost_noACTH` and then update `data_to_match` to not include the two arguments for ACTH data. To use the Yehuda Control group data, this would look like:\n",
    "\n",
    "    data_to_match = [yehuda.controlCortisol[:,0], yehuda.controlCortisol[:,1]]\n",
    "    return optimize.SSE_cost_noACTH(data_to_match[0], data_to_match[1], simData)\n",
    "\n",
    "For data without ACTH concentrations, you will also need to comment out the current definition of `y0` and uncomment the following line (and change the IC to the desired value for ACTH):\n",
    "\n",
    "    #y0 = [0, 0, 0, 10, data_to_match[1][0]]\n",
    "    \n",
    "At this point, you're ready to run the parameter optimization, so run all of the cells under the heading **Run the Optimization**.\n",
    "\n",
    "The cell directly under the heading **Save Output to File** should again have the filename changed to something that reflects the data set you're matching now. For instance, the filename root when matching the smoothed Carroll Control group and optimizing ICs would become:\n",
    "\n",
    "    filename_root = 'malekModel_output/carroll-control-smooth-5-iterations-ICopt'\n",
    "            \n",
    "Finally, the cells under the heading **Plots** should be run again to generate graphs. The same process of giving inputs to the object dialog will be performed and then the method `make_graphs()` should be run with any optional arguments desired.\n",
    "\n",
    "## Running Without Parameter Optimization <a name=\"noOptInstructions\" />\n",
    "\n",
    "To run the model with any set of paramaters you desire, without optimization, you can use the cells under the heading **No Optimization Run**. Change the parameters and initial conditions defined under the heading **Parameters and Initial Conditions**, and then run the cell containing the following line:\n",
    "\n",
    "    data_no_opt = model(authors_params, y0)\n",
    "    \n",
    "Then run the cells under **Plots** to create graphs as described in the sections regarding simulations with parameter optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports <a name=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as sco\n",
    "from scipy import optimize\n",
    "from scipy.interpolate import interp1d\n",
    "import mpld3\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "from VeVaPy import DEsolver, optimize\n",
    "from VeVaPy.dataImport import data\n",
    "from VeVaPy.visualize import Visualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters and Initial Conditions <a name=\"params\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial conditions\n",
    "# order is: LPS endotoxin, TNF-alpha, IL-6, ACTH, Cortisol\n",
    "\n",
    "y0 = [0, 0, 0,14.47489,1.903323]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authors' published parameters\n",
    "\n",
    "e_P = 0.05\n",
    "e_T = 0.038\n",
    "e_S = 0.02\n",
    "e_A = 0.04\n",
    "e_C = 0.01\n",
    "d_1 = 0.026\n",
    "d_2 = 0.068\n",
    "d_3 = 0.063\n",
    "d_4 = 2.37\n",
    "d_5 = 9.39\n",
    "d_6 = 0.35\n",
    "k = 0.0504\n",
    "tau_1 = 10\n",
    "tau_2 = 10\n",
    "m_1 = 4\n",
    "m_2 = 4\n",
    "c = 6.11\n",
    "a = 21\n",
    "h = 7.66\n",
    "alpha = 0.28\n",
    "x_1 = 3.25\n",
    "x_2 = 0.86\n",
    "x_3 = 0.016\n",
    "x_4 = 6.11\n",
    "x_5 = 1.39\n",
    "x_6 = 1.57\n",
    "x_7 = 6.11\n",
    "x_8 = 1.72\n",
    "x_9 = 0.87\n",
    "x_10 = 0.94\n",
    "x_11 = 1.87\n",
    "x_12 = 1.97\n",
    "\n",
    "authors_params = [e_P, e_T, e_S, e_A, e_C, d_1, d_2, d_3, d_4, d_5, d_6, k, tau_1, tau_2, m_1, m_2, c, a, h, alpha, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute bounds based on +- 10%\n",
    "bound = alpha\n",
    "print(bound - bound*.25)\n",
    "print(bound + bound*.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bounds for parameter optimization\n",
    "# starting with +- 10% since we do not have published ranges in the paper\n",
    "# order is: e_P, e_T, e_S, e_A, e_C, d_1, d_2, d_3, d_4, d_5, d_6, k, tau_1, tau_2, m_1, m_2, c, a, h, alpha, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12\n",
    "# the authors included 95% CI for several of the parameters, so we have used those intervals as the bounds for\n",
    "#     the parametrs they included\n",
    "# the ones included are: x_1, x_2, x_3, x_5, x_6, x_8, x_9, x_10, x_11, x_12, k, d_1, d_2, d_3, d_4, d_5, d_6\n",
    "bounds = [(0.045, 0.055), (0.0342, 0.0418), (0.018, 0.022), (0.036, 0.044), (0.009, 0.011), (0.021, 2.21), (0.052, 1.39), (0.0074, 0.3), (0.71, 2.63), (8.59, 13.55), (0.27, 2.46), (0.03, 0.54), (9., 11.), (9., 11.), (3.6, 4.4), (3.6, 4.4), (5.499, 6.721), (18.9, 23.1), (6.894, 8.426), (0.252, 0.308), (2.62, 6.13), (0.09, 2.02), (0.013, 3.4), (5.499, 6.721), (0.81, 3.79), (2.81, 5.68), (4.499, 6.721), (0.99, 5.16), (0.27, 4.07), (0.05, 2.6), (0.2, 5.43), (1.47, 6.45)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bounds for parameter optimization\n",
    "# +- 25% since we do not have published ranges in the paper\n",
    "# order is: e_P, e_T, e_S, e_A, e_C, d_1, d_2, d_3, d_4, d_5, d_6, k, tau_1, tau_2, m_1, m_2, c, a, h, alpha, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12\n",
    "bounds = [(0.037500000000000006, 0.0625), (0.028499999999999998, 0.0475), (0.015, 0.025), (0.03, 0.05), (0.0075, 0.0125), (0.021, 2.21), (0.052, 1.39), (0.0074, 0.3), (0.71, 2.63), (8.59, 13.55), (0.27, 2.46), (0.03, 0.54), (7.5, 12.5), (7.5, 12.5), (3., 5.), (3., 5.), (4.5825, 7.6375), (15.75, 26.25), (5.745, 9.575), (0.21, 0.35), (2.62, 6.13), (0.09, 2.02), (0.013, 3.4), (5.499, 6.721), (0.81, 3.79), (2.81, 5.68), (4.499, 6.721), (0.99, 5.16), (0.27, 4.07), (0.05, 2.6), (0.2, 5.43), (1.47, 6.45)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define time interval for integration\n",
    "\n",
    "# time interval and step definition\n",
    "# all data sets end on 1440.0 or earlier except the Golier cortisol sets,\n",
    "# they end on 1455.0, so I should set t_end = 1455.01 when matching them\n",
    "#t_start = -0.01\n",
    "#t_end = 1455.01\n",
    "#t_step = 0.01\n",
    "\n",
    "# for matching Nelson data, use these values of t_start, t_end and t_step\n",
    "t_start = -0.5\n",
    "t_end = 140.5\n",
    "t_step = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put Raw Data into Arrays <a name=\"rawdata\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the data class for each data set contained in the VeVaPy library, and set the time\n",
    "# scale to hours.\n",
    "yehuda = data(\"yehuda\", \"minutes\")\n",
    "carroll = data(\"carroll\", \"minutes\")\n",
    "golier = data(\"golier\", \"minutes\")\n",
    "bremner = data(\"bremner\", \"minutes\")\n",
    "nelson = data(\"nelson\", \"minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Data Sets <a name=\"plotdata\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows = 3, figsize = (15,15))\n",
    "\n",
    "ax1.plot(yehuda.controlCortisol[:,0], yehuda.controlCortisol[:,1], label = \"Control Group Cortisol\")\n",
    "ax1.plot(yehuda.controlCortisol_smooth[:,0], yehuda.controlCortisol_smooth[:,1], label = \"Control Group Cortisol - Smoothed\")\n",
    "ax1.set(xlabel=\"Time (hours)\", ylabel=\"Cortisol (micrograms/dL)\")\n",
    "ax1.legend(loc=\"lower right\", shadow = True, fancybox = True)\n",
    "\n",
    "ax2.plot(yehuda.PTSDCortisol[:,0], yehuda.PTSDCortisol[:,1], label = \"PTSD Group Cortisol\")\n",
    "ax2.plot(yehuda.PTSDCortisol_smooth[:,0], yehuda.PTSDCortisol_smooth[:,1], label = \"PTSD Group Cortisol - Smoothed\")\n",
    "ax2.set(xlabel=\"Time (hours)\", ylabel=\"Cortisol (micrograms/dL)\")\n",
    "ax2.legend(loc=\"lower right\", shadow = True, fancybox = True)\n",
    "\n",
    "ax3.plot(yehuda.depressedCortisol[:,0], yehuda.depressedCortisol[:,1], label = \"Depression Group Cortisol\")\n",
    "ax3.plot(yehuda.depressedCortisol_smooth[:,0], yehuda.depressedCortisol_smooth[:,1], label = \"Depression Group Cortisol - Smoothed\")\n",
    "ax3.set(xlabel=\"Time (hours)\", ylabel=\"Cortisol (micrograms/dL)\")\n",
    "ax3.legend(loc=\"lower right\", shadow = True, fancybox = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mpld3.enable_notebook()\n",
    "%matplotlib inline\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(nrows = 4, figsize = (15,15))\n",
    "\n",
    "ax1.plot(carroll.controlCortisol_rearr[:,0], carroll.controlCortisol_rearr[:,1], 'b', label = \"Control\")\n",
    "ax1.plot(carroll.HCDepressedCortisol_rearr[:,0], carroll.HCDepressedCortisol_rearr[:,1], 'r', label = \"High Cortisol Depressed\")\n",
    "ax1.plot(carroll.controlCortisol_rearr_smooth[:,0], carroll.controlCortisol_rearr_smooth[:,1], label = \"Control - Smoothed\")\n",
    "ax1.plot(carroll.HCDepressedCortisol_rearr_smooth[:,0], carroll.HCDepressedCortisol_rearr_smooth[:,1], label = \"High Cortisol Depressed - Smoothed\")\n",
    "ax1.set(xlabel=\"Time (hours)\", ylabel=\"Cortisol (micrograms/dL)\")\n",
    "ax1.legend(loc=\"upper right\", shadow = True, fancybox = True)\n",
    "\n",
    "ax2.plot(carroll.controlCortisol_rearr[:,0], carroll.controlCortisol_rearr[:,1], 'b', label = \"Control\")\n",
    "ax2.plot(carroll.LCDepressedCortisol_rearr[:,0], carroll.LCDepressedCortisol_rearr[:,1], 'g', label = \"Low Cortisol Depressed\")\n",
    "ax2.plot(carroll.controlCortisol_rearr_smooth[:,0], carroll.controlCortisol_rearr_smooth[:,1], label = \"Control - Smoothed\")\n",
    "ax2.plot(carroll.LCDepressedCortisol_rearr_smooth[:,0], carroll.LCDepressedCortisol_rearr_smooth[:,1], label = \"Low Cortisol Depressed - Smoothed\")\n",
    "ax2.set(xlabel=\"Time (hours)\", ylabel=\"Cortisol (micrograms/dL)\")\n",
    "ax2.legend(loc=\"upper right\", shadow = True, fancybox = True)\n",
    "\n",
    "ax3.plot(carroll.controlACTH_rearr[:,0], carroll.controlACTH_rearr[:,1], 'b', label = \"Control\")\n",
    "ax3.plot(carroll.HCDepressedACTH_rearr[:,0], carroll.HCDepressedACTH_rearr[:,1], 'r', label = \"High Cortisol Depressed\")\n",
    "ax3.plot(carroll.controlACTH_rearr_smooth[:,0], carroll.controlACTH_rearr_smooth[:,1], label = \"Control - Smoothed\")\n",
    "ax3.plot(carroll.HCDepressedACTH_rearr_smooth[:,0], carroll.HCDepressedACTH_rearr_smooth[:,1], label = \"High Cortisol Depressed - Smoothed\")\n",
    "ax3.set(xlabel=\"Time (hours)\", ylabel=\"ACTH (pg/mL)\")\n",
    "ax3.legend(loc=\"upper right\", shadow = True, fancybox = True)\n",
    "\n",
    "ax4.plot(carroll.controlACTH_rearr[:,0], carroll.controlACTH_rearr[:,1], 'b', label = \"Control\")\n",
    "ax4.plot(carroll.LCDepressedACTH_rearr[:,0], carroll.LCDepressedACTH_rearr[:,1], 'g', label = \"Low Cortisol Depressed\")\n",
    "ax4.plot(carroll.controlACTH_rearr_smooth[:,0], carroll.controlACTH_rearr_smooth[:,1], label = \"Control - Smoothed\")\n",
    "ax4.plot(carroll.LCDepressedACTH_rearr_smooth[:,0], carroll.LCDepressedACTH_rearr_smooth[:,1], label = \"Low Cortisol Depressed - Smoothed\")\n",
    "ax4.set(xlabel=\"Time (hours)\", ylabel=\"ACTH (pg/mL)\")\n",
    "ax4.legend(loc=\"upper right\", shadow = True, fancybox = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4, ax5, ax6) = plt.subplots(nrows = 6, figsize = (15,20))\n",
    "\n",
    "ax1.plot(golier.PTSDCortisol_rearr_smooth[:,0], golier.PTSDCortisol_rearr_smooth[:,1], label = \"Trauma Exposed PTSD Cortisol - Smoothed\")\n",
    "ax1.plot(golier.PTSDCortisol_rearr[:,0], golier.PTSDCortisol_rearr[:,1], label = \"Trauma Exposed PTSD Cortisol\")\n",
    "ax1.set(xlabel=\"Time (hours)\", ylabel=\"Cortisol (mg/dL)\")\n",
    "ax1.legend(loc=\"lower right\", shadow = True, fancybox = True)\n",
    "\n",
    "ax2.plot(golier.nonPTSDTraumaExposedCortisol_rearr_smooth[:,0], golier.nonPTSDTraumaExposedCortisol_rearr_smooth[:,1], label = \"Trauma Exposed Non-PTSD Cortisol - Smoothed\")\n",
    "ax2.plot(golier.nonPTSDTraumaExposedCortisol_rearr[:,0], golier.nonPTSDTraumaExposedCortisol_rearr[:,1], label = \"Trauma Exposed Non-PTSD Cortisol\")\n",
    "ax2.set(xlabel=\"Time (hours)\", ylabel=\"Cortisol (mg/dL)\")\n",
    "ax2.legend(loc=\"lower right\", shadow = True, fancybox = True)\n",
    "\n",
    "ax3.plot(golier.nonPTSDNonExposedCortisol_rearr_smooth[:,0], golier.nonPTSDNonExposedCortisol_rearr_smooth[:,1], label = \"Non-Exposed Non-PTSD Cortisol - Smoothed\")\n",
    "ax3.plot(golier.nonPTSDNonExposedCortisol_rearr[:,0], golier.nonPTSDNonExposedCortisol_rearr[:,1], label = \"Non-Exposed Non-PTSD Cortisol\")\n",
    "ax3.set(xlabel=\"Time (hours)\", ylabel=\"Cortisol (mg/dL)\")\n",
    "ax3.legend(loc=\"lower right\", shadow = True, fancybox = True)\n",
    "\n",
    "ax4.plot(golier.PTSDACTH_rearr_smooth[:,0], golier.PTSDACTH_rearr_smooth[:,1], label = \"Trauma Exposed PTSD ACTH - Smoothed\")\n",
    "ax4.plot(golier.PTSDACTH_rearr[:,0], golier.PTSDACTH_rearr[:,1], label = \"Trauma Exposed PTSD ACTH\")\n",
    "ax4.set(xlabel=\"Time (hours)\", ylabel=\"ACTH (pg/mL)\")\n",
    "ax4.legend(loc=\"lower right\", shadow = True, fancybox = True)\n",
    "\n",
    "ax5.plot(golier.nonPTSDTraumaExposedACTH_rearr_smooth[:,0], golier.nonPTSDTraumaExposedACTH_rearr_smooth[:,1], label = \"Trauma Exposed Non-PTSD ACTH - Smoothed\")\n",
    "ax5.plot(golier.nonPTSDTraumaExposedACTH_rearr[:,0], golier.nonPTSDTraumaExposedACTH_rearr[:,1], label = \"Trauma Exposed Non-PTSD ACTH\")\n",
    "ax5.set(xlabel=\"Time (hours)\", ylabel=\"ACTH (pg/mL)\")\n",
    "ax5.legend(loc=\"lower right\", shadow = True, fancybox = True)\n",
    "\n",
    "ax6.plot(golier.nonPTSDNonExposedACTH_rearr_smooth[:,0], golier.nonPTSDNonExposedACTH_rearr_smooth[:,1], label = \"Non-Exposed Non-PTSD ACTH - Smoothed\")\n",
    "ax6.plot(golier.nonPTSDNonExposedACTH_rearr[:,0], golier.nonPTSDNonExposedACTH_rearr[:,1], label = \"Non-Exposed Non-PTSD ACTH\")\n",
    "ax6.set(xlabel=\"Time (hours)\", ylabel=\"ACTH (pg/mL)\")\n",
    "ax6.legend(loc=\"lower right\", shadow = True, fancybox = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows = 3, figsize = (15,15))\n",
    "\n",
    "ax1.plot(bremner.abusedPTSDCortisol_rearr_smooth[:,0], bremner.abusedPTSDCortisol_rearr_smooth[:,1], label = \"Abused PTSD Cortisol - Smoothed\")\n",
    "ax1.plot(bremner.abusedPTSDCortisol_rearr[:,0], bremner.abusedPTSDCortisol_rearr[:,1], label = \"Abused PTSD Cortisol\")\n",
    "ax1.set(xlabel=\"Time (hours)\", ylabel=\"Cortisol (microg/dL)\")\n",
    "ax1.legend(loc=\"lower right\", shadow = True, fancybox = True)\n",
    "\n",
    "ax2.plot(bremner.nonAbusedPTSDCortisol_rearr_smooth[:,0], bremner.nonAbusedPTSDCortisol_rearr_smooth[:,1], label = \"Non-Abused PTSD Cortisol - Smoothed\")\n",
    "ax2.plot(bremner.nonAbusedPTSDCortisol_rearr[:,0], bremner.nonAbusedPTSDCortisol_rearr[:,1], label = \"Non-Abused PTSD Cortisol\")\n",
    "ax2.set(xlabel=\"Time (hours)\", ylabel=\"Cortisol (microg/dL)\")\n",
    "ax2.legend(loc=\"lower right\", shadow = True, fancybox = True)\n",
    "\n",
    "ax3.plot(bremner.nonAbusedNonPTSDCortisol_rearr_smooth[:,0], bremner.nonAbusedNonPTSDCortisol_rearr_smooth[:,1], label = \"Non-Abused Non-PTSD Cortisol - Smoothed\")\n",
    "ax3.plot(bremner.nonAbusedNonPTSDCortisol_rearr[:,0], bremner.nonAbusedNonPTSDCortisol_rearr[:,1], label = \"Non-Abused Non-PTSD Cortisol\")\n",
    "ax3.set(xlabel=\"Time (hours)\", ylabel=\"Cortisol (microg/dL)\")\n",
    "ax3.legend(loc=\"lower left\", shadow = True, fancybox = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows = 2, figsize = (15, 15))\n",
    "\n",
    "ax1.plot(nelson.ACTH[:,0], nelson.ACTH[:,1])\n",
    "ax2.plot(nelson.cortisol[:,0], nelson.cortisol[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Function -- Includes ODE Solver <a name=\"modelfunction\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(params, ics):\n",
    "    # function containing the system, to be called by solver\n",
    "    def ode_system(t, y):\n",
    "        # initialize array to hold ODE function values\n",
    "        dy = np.zeros(5)\n",
    "        \n",
    "        # define parameter values\n",
    "        [e_P, e_T, e_S, e_A, e_C, d_1, d_2, d_3, d_4, d_5, d_6, k, tau_1, tau_2, m_1, m_2, c, a, h, alpha, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12] = params\n",
    "\n",
    "        # the ODE system itself\n",
    "        dy[0] = -e_P*y[0] - d_1*(y[1]/(x_1 + y[1]))*(y[2]/(x_2 + y[2]))*y[0]\n",
    "        dy[1] = -e_T*y[1] + k*(y[0]/(x_3 + y[0])) + ((d_2/(x_4 + y[4])) + (d_3/(x_5 + y[2])))*(y[1]/(x_6 + y[1]))\n",
    "        dy[2] = -e_S*y[2] + d_4*(1/(x_7 + y[4]))*(y[1]/(x_8 + y[1]))\n",
    "        # to include circadian input function, uncomment line with E(t) included in ACTH\n",
    "        #dy[3] = -e_A*y[3] + E(t)*h*((c**m_1)/(c**m_1 + DEsolver.delayedCORT**m_1)) + d_5*(y[2]/(x_9 + y[2]))*(y[1]/(x_10 + y[1]))\n",
    "        dy[3] = -e_A*y[3] + h*((c**m_1)/(c**m_1 + DEsolver.delayedCORT**m_1)) + d_5*(y[2]/(x_9 + y[2]))*(y[1]/(x_10 + y[1]))\n",
    "        dy[4] = -e_C*y[4] + alpha*((DEsolver.delayedACTH**m_2)/(DEsolver.delayedACTH**m_2 + a**m_2)) + d_6*(y[2]/(x_11 + y[2]))*(y[1]/(x_12 + y[1]))\n",
    "        \n",
    "        return dy\n",
    "    \n",
    "    def E(t):\n",
    "        return (0.6 + 0.171*np.sin(((2*np.pi)/(24*60))*t) - 0.4698*np.cos(((2*np.pi)/(24*60))*t))\n",
    "    \n",
    "    # Call the solve() function from my DEsolver module, and pass all of the information it needs.\n",
    "    # Arguments are as follows: ODE function to solve, array of initial conditions, start time, step size, end time, \n",
    "    # The last five arguments are optional (leave blank for ODE systems) for delay differential equation systems,\n",
    "    #  tau1 is the delay in ACTH, tau2 is the delay in CORT, and delay is an array of booleans to set whether \n",
    "    #  we use delays in [CRH, ACTH, CORT]\n",
    "    #\n",
    "    # Because of the fact that this model has equations for LPS, TNF-alpha and IL-6 before the equations for ACTH & Cortisol,\n",
    "    #  we need to change the optional arguments y_index1 to 3 (for the index of ACTH in the array y), and y_index2 to 4 (for the \n",
    "    #  index of cortisol in the array y). \n",
    "    timeSeries = DEsolver.solve(ode_system, ics, t_start, t_step, t_end, y_index1 = 3, y_index2 = 4, tau1 = tau_1, tau2 = tau_2, delay = [False, True, True], delay_rough = True)\n",
    "    return timeSeries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Function Definition <a name=\"cost\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_fun(params):\n",
    "    global y0, data_to_match\n",
    "    simData = model(params, y0)\n",
    "\n",
    "    # To optimize ICs for the inflammatory cytokines, uncomment below and comment the line starting with simData above\n",
    "    #y0 = [params[0], params[1], params[2], y0[3], y0[4]]\n",
    "    #simData = model(params[3:], y0)\n",
    "    \n",
    "    # To optimize the IC for ACTH (and not the inflammatory cytokines), in the case that you are matching basal data\n",
    "    #  with only cortisol concentrations, uncomment the following lines\n",
    "    #y0 = [0, 0, 0, params[0], y0[4]]\n",
    "    #simData = model(params[1:], y0)\n",
    "    \n",
    "    # We need to define the optional arguments for ACTH_index and CORT_index because\n",
    "    #  the equations for this model have them in non-standard indices. In this\n",
    "    #  case, ACTH is in index 3 of y0 and cortisol is in index 4 of y0\n",
    "    return optimize.SSE_cost(data_to_match[0], data_to_match[1], data_to_match[2], data_to_match[3], simData, ACTH_index = 3, CORT_index = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Optimization <a name=\"run\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data set to match with the parameter optimization algorithm.\n",
    "# Requires 4 indices, in the order:\n",
    "# ACTH time steps, ACTH data, Cortisol time steps, Cortisol data\n",
    "data_to_match = [nelson.ACTH[:,0], nelson.ACTH[:,1], nelson.cortisol[:,0], nelson.cortisol[:,1]]\n",
    "\n",
    "# For matching data with only cortisol concentrations, use the following line and change the data sets as desired:\n",
    "#data_to_match = [yehuda.controlCortisol[:,0], yehuda.controlCortisol[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial conditions\n",
    "# order: LPS endotoxin, TNF-alpha, IL-6, ACTH, CORT\n",
    "\n",
    "# Setting the inflammation-related ICs to zero turns the model into one of just the HPA axis\n",
    "y0 = [0, 0, 0, data_to_match[1][0], data_to_match[3][0]]\n",
    "\n",
    "# For matching data with only cortisol concentrations, use the following line and change the ICs as desired:\n",
    "#y0 = [0, 0, 0, 10, data_to_match[1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We call the run() method of the optimize module, which will run the parameter optimization given the arguments we pass\n",
    "# Required arguments are the cost function, the model, and the real-world data we want to match\n",
    "#\n",
    "# Optional arguments include the initial conditions we want to optimize (if any), the number of iterations to run,\n",
    "#  the maximum number of optimization steps per iteration of the algorithm, the algorithm to use (defaults to \n",
    "#  differential_evolution), and the popsize to use (larger popsize gives more accurate optimization but is more \n",
    "#  computationally expensive) \n",
    "opt_pars, simData_all = optimize.run(cost_fun, model, data_to_match, y0, bounds, num_iter=5, popsize=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Output to File <a name=\"saveoutput\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the root filename, this will have the array name appended to it\n",
    "#  to make the filename of the Excel files\n",
    "filename_root = \"malekModel_output/nelson-patientMean-5-iterations-ICOpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pandas DataFrame object for opt_pars\n",
    "# I've typed out each individual heading for the parameter names that were\n",
    "#  optimized, and assigned the correct column of opt_pars to them\n",
    "#\n",
    "# NOTE: I've been unable to get this code to work for 1 iteration of parameter optimization (only for opt_pars)\n",
    "# Hopefully in the near future I'll get it worked out, but for some reason I can't get it to be output as a single row\n",
    "# with 21 columns. It'll only output as a single column with 21 rows.\n",
    "df_opt_pars = pd.DataFrame(opt_pars, columns=['Cost',\n",
    "                                              'e_P',\n",
    "                                              'e_T',\n",
    "                                              'e_S',\n",
    "                                              'e_A',\n",
    "                                              'e_C',\n",
    "                                              'd_1',\n",
    "                                              'd_2',\n",
    "                                              'd_3',\n",
    "                                              'd_4',\n",
    "                                              'd_5',\n",
    "                                              'd_6',\n",
    "                                              'k',\n",
    "                                              'tau_1',\n",
    "                                              'tau_2',\n",
    "                                              'm_1',\n",
    "                                              'm_2',\n",
    "                                              'c',\n",
    "                                              'a',\n",
    "                                              'h',\n",
    "                                              'alpha',\n",
    "                                              'x_1',\n",
    "                                              'x_2',\n",
    "                                              'x_3',\n",
    "                                              'x_4',\n",
    "                                              'x_5',\n",
    "                                              'x_6',\n",
    "                                              'x_7',\n",
    "                                              'x_8',\n",
    "                                              'x_9',\n",
    "                                              'x_10',\n",
    "                                              'x_11',\n",
    "                                              'x_12'])\n",
    "# Create the pandas DataFrame object for simData_all\n",
    "# I've typed out each individual heading for the variables and iterations,\n",
    "# and assigned the correct column of simData_all to them\n",
    "df_simData_all = pd.DataFrame(simData_all, columns=['Iteration 1 Time',\n",
    "                                                    'Iteration 1 ACTH',\n",
    "                                                    'Iteration 1 Cortisol',\n",
    "                                                    'Iteration 1 LPS',\n",
    "                                                    'Iteration 1 TNF-alpha',\n",
    "                                                    'Iteration 1 IL-6',\n",
    "                                                    'Iteration 2 Time',\n",
    "                                                    'Iteration 2 ACTH',\n",
    "                                                    'Iteration 2 Cortisol',\n",
    "                                                    'Iteration 2 LPS',\n",
    "                                                    'Iteration 2 TNF-alpha',\n",
    "                                                    'Iteration 2 IL-6',\n",
    "                                                    'Iteration 3 Time',\n",
    "                                                    'Iteration 3 ACTH',\n",
    "                                                    'Iteration 3 Cortisol',\n",
    "                                                    'Iteration 3 LPS',\n",
    "                                                    'Iteration 3 TNF-alpha',\n",
    "                                                    'Iteration 3 IL-6',\n",
    "                                                    'Iteration 4 Time',\n",
    "                                                    'Iteration 4 ACTH',\n",
    "                                                    'Iteration 4 Cortisol',\n",
    "                                                    'Iteration 4 LPS',\n",
    "                                                    'Iteration 4 TNF-alpha',\n",
    "                                                    'Iteration 4 IL-6',\n",
    "                                                    'Iteration 5 Time',\n",
    "                                                    'Iteration 5 ACTH',\n",
    "                                                    'Iteration 5 Cortisol',\n",
    "                                                    'Iteration 5 LPS',\n",
    "                                                    'Iteration 5 TNF-alpha',\n",
    "                                                    'Iteration 5 IL-6'])\n",
    "\n",
    "# Create an instance of the ExcelWriter class and open the file using a with statement\n",
    "with pd.ExcelWriter(filename_root+\".xlsx\") as writer:\n",
    "    # Define the header format, so that it's bold, text is wrapped, it has a \n",
    "    #  colored background and a border\n",
    "    header_format = writer.book.add_format({\n",
    "        'bold': True,\n",
    "        'text_wrap': True,\n",
    "        'valign': 'top',\n",
    "        'fg_color': '#D7E4BC',\n",
    "        'border': 1\n",
    "    })\n",
    "    \n",
    "    # Write the opt_pars array to a sheet in the file, we skip adding in the headers here and add them with the above\n",
    "    #  format afterwards. We also change the row index to start at 1, rather than 0.\n",
    "    df_opt_pars.index = list(range(1,len(opt_pars[:,0])+1))\n",
    "    df_opt_pars.to_excel(writer, sheet_name=\"Optimized Parameters\", startrow=1, header=False)\n",
    "    \n",
    "    # Write the simData_all array to another sheet in the file, we skip adding in the headers here and add them with the above\n",
    "    #  format afterwards. We also disable the row index numbers, as they are not necessary here.\n",
    "    df_simData_all.to_excel(writer, sheet_name=\"Simulated Concentration Data\", startrow=1, header=False, index=False)\n",
    "    \n",
    "    # Loop through each header in opt_pars DataFrame and write to the sheet with formatting\n",
    "    for col,val in enumerate(df_opt_pars.columns.values):\n",
    "        # We write in the sheet \"Optimized Parameters\" in the first row, starting with the second column \n",
    "        #  (because of the row indices), using the headers from the DataFrame and the header format we defined above\n",
    "        writer.sheets[\"Optimized Parameters\"].write(0, col+1, val, header_format)\n",
    "    \n",
    "    # Loop through each header in simData_all DataFrame and write to the sheet with formatting\n",
    "    for col,val in enumerate(df_simData_all.columns.values):\n",
    "        # We write in the sheet \"Simulated Concentration Data\" in the first row, starting with the first column \n",
    "        #  (because we turned off the row indices), using the headers from the DataFrame and \n",
    "        #  the header format we defined above\n",
    "        writer.sheets[\"Simulated Concentration Data\"].write(0, col, val, header_format)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the initial conditions and bounds to text files, also.\n",
    "np.savetxt(filename_root+'-initial-conditions.txt', y0)\n",
    "np.savetxt(filename_root+'-bounds.txt', bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Means and Std Devations of Parameters and Output as Table <a name=\"paramtable\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute parameter means and standard deviations\n",
    "e_P_mean = np.mean(opt_pars[:,1])\n",
    "e_P_std = np.std(opt_pars[:,1])\n",
    "e_T_mean = np.mean(opt_pars[:,2])\n",
    "e_T_std = np.std(opt_pars[:,2])\n",
    "e_S_mean = np.mean(opt_pars[:,3])\n",
    "e_S_std = np.std(opt_pars[:,3])\n",
    "e_A_mean = np.mean(opt_pars[:,4])\n",
    "e_A_std = np.std(opt_pars[:,4])\n",
    "e_C_mean = np.mean(opt_pars[:,5])\n",
    "e_C_std = np.std(opt_pars[:,5])\n",
    "d_1_mean = np.mean(opt_pars[:,6])\n",
    "d_1_std = np.std(opt_pars[:,6])\n",
    "d_2_mean = np.mean(opt_pars[:,7])\n",
    "d_2_std = np.std(opt_pars[:,7])\n",
    "d_3_mean = np.mean(opt_pars[:,8])\n",
    "d_3_std = np.std(opt_pars[:,8])\n",
    "d_4_mean = np.mean(opt_pars[:,9])\n",
    "d_4_std = np.std(opt_pars[:,9])\n",
    "d_5_mean = np.mean(opt_pars[:,10])\n",
    "d_5_std = np.std(opt_pars[:,10])\n",
    "d_6_mean = np.mean(opt_pars[:,11])\n",
    "d_6_std = np.std(opt_pars[:,11])\n",
    "k_mean = np.mean(opt_pars[:,12])\n",
    "k_std = np.std(opt_pars[:,12])\n",
    "tau_1_mean = np.mean(opt_pars[:,13])\n",
    "tau_1_std = np.std(opt_pars[:,13])\n",
    "tau_2_mean = np.mean(opt_pars[:,14])\n",
    "tau_2_std = np.std(opt_pars[:,14])\n",
    "m_1_mean = np.mean(opt_pars[:,15])\n",
    "m_1_std = np.std(opt_pars[:,15])\n",
    "m_2_mean = np.mean(opt_pars[:,16])\n",
    "m_2_std = np.std(opt_pars[:,16])\n",
    "c_mean = np.mean(opt_pars[:,17])\n",
    "c_std = np.std(opt_pars[:,17])\n",
    "a_mean = np.mean(opt_pars[:,18])\n",
    "a_std = np.std(opt_pars[:,18])\n",
    "h_mean = np.mean(opt_pars[:,19])\n",
    "h_std = np.std(opt_pars[:,19])\n",
    "alpha_mean = np.mean(opt_pars[:,20])\n",
    "alpha_std = np.std(opt_pars[:,20])\n",
    "x_1_mean = np.mean(opt_pars[:,21])\n",
    "x_1_std = np.std(opt_pars[:,21])\n",
    "x_2_mean = np.mean(opt_pars[:,22])\n",
    "x_2_std = np.std(opt_pars[:,22])\n",
    "x_3_mean = np.mean(opt_pars[:,23])\n",
    "x_3_std = np.std(opt_pars[:,23])\n",
    "x_4_mean = np.mean(opt_pars[:,24])\n",
    "x_4_std = np.std(opt_pars[:,24])\n",
    "x_5_mean = np.mean(opt_pars[:,25])\n",
    "x_5_std = np.std(opt_pars[:,25])\n",
    "x_6_mean = np.mean(opt_pars[:,26])\n",
    "x_6_std = np.std(opt_pars[:,26])\n",
    "x_7_mean = np.mean(opt_pars[:,27])\n",
    "x_7_std = np.std(opt_pars[:,27])\n",
    "x_8_mean = np.mean(opt_pars[:,28])\n",
    "x_8_std = np.std(opt_pars[:,28])\n",
    "x_9_mean = np.mean(opt_pars[:,29])\n",
    "x_9_std = np.std(opt_pars[:,29])\n",
    "x_10_mean = np.mean(opt_pars[:,30])\n",
    "x_10_std = np.std(opt_pars[:,30])\n",
    "x_11_mean = np.mean(opt_pars[:,31])\n",
    "x_11_std = np.std(opt_pars[:,31])\n",
    "x_12_mean = np.mean(opt_pars[:,32])\n",
    "x_12_std = np.std(opt_pars[:,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a table of parameter means and standard deviations\n",
    "print(tabulate([[\"e_P\", \"%f +- %f\" % (e_P_mean, e_P_std)], [\"e_T\", \"%f +- %f\" % (e_T_mean, e_T_std)], [\"e_S\", \"%f +- %f\" % (e_S_mean, e_S_std)], [\"e_A\", \"%f +- %f\" % (e_A_mean, e_A_std)], [\"e_C\", \"%f +- %f\" % (e_C_mean, e_C_std)], [\"d_1\", \"%f +- %f\" % (d_1_mean, d_1_std)], [\"d_2\", \"%f +- %f\" % (d_2_mean, d_2_std)], [\"d_3\", \"%f +- %f\" % (d_3_mean, d_3_std)], [\"d_4\", \"%f +- %f\" % (d_4_mean, d_4_std)], [\"d_5\", \"%f +- %f\" % (d_5_mean, d_5_std)], [\"d_6\", \"%f +- %f\" % (d_6_mean, d_6_std)], [\"k\", \"%f +- %f\" % (k_mean, k_std)], [\"tau_1\", \"%f +- %f\" % (tau_1_mean, tau_1_std)], [\"tau_2\", \"%f +- %f\" % (tau_2_mean, tau_2_std)], [\"m_1\", \"%f +- %f\" % (m_1_mean, m_1_std)], [\"m_2\", \"%f +- %f\" % (m_2_mean, m_2_std)], [\"c\", \"%f +- %f\" % (c_mean, c_std)], [\"a\", \"%f +- %f\" % (a_mean, a_std)], [\"h\", \"%f +- %f\" % (h_mean, h_std)], [\"alpha\", \"%f +- %f\" % (alpha_mean, alpha_std)], [\"x_1\", \"%f +- %f\" % (x_1_mean, x_1_std)], [\"x_2\", \"%f +- %f\" % (x_2_mean, x_2_std)], [\"x_3\", \"%f +- %f\" % (x_3_mean, x_3_std)], [\"x_4\", \"%f +- %f\" % (x_4_mean, x_4_std)], [\"x_5\", \"%f +- %f\" % (x_5_mean, x_5_std)], [\"x_6\", \"%f +- %f\" % (x_6_mean, x_6_std)], [\"x_7\", \"%f +- %f\" % (x_7_mean, x_7_std)], [\"x_8\", \"%f +- %f\" % (x_8_mean, x_8_std)], [\"x_9\", \"%f +- %f\" % (x_9_mean, x_9_std)], [\"x_10\", \"%f +- %f\" % (x_10_mean, x_10_std)], [\"x_11\", \"%f +- %f\" % (x_11_mean, x_11_std)], [\"x_12\", \"%f +- %f\" % (x_12_mean, x_12_std)]], headers = [\"Parameter\", \"Mean +- Standard Deviation\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save means and std devs to a file\n",
    "np.savetxt(filename_root+'-param-means-stds.txt', [e_P_mean, e_P_std, e_T_mean, e_T_std, e_S_mean, e_S_std, e_A_mean, e_A_std, e_C_mean, e_C_std, d_1_mean, d_1_std, d_2_mean, d_2_std, d_3_mean, d_3_std, d_4_mean, d_4_std, d_5_mean, d_5_std, d_6_mean, d_6_std, k_mean, k_std, tau_1_mean, tau_1_std, tau_2_mean, tau_2_std, m_1_mean, m_1_std, m_2_mean, m_2_std, c_mean, c_std, a_mean, a_std, h_mean, h_std, alpha_mean, alpha_std, x_1_mean, x_1_std, x_2_mean, x_2_std, x_3_mean, x_3_std, x_4_mean, x_4_std, x_5_mean, x_5_std, x_6_mean, x_6_std, x_7_mean, x_7_std, x_8_mean, x_8_std, x_9_mean, x_9_std, x_10_mean, x_10_std, x_11_mean, x_11_std, x_12_mean, x_12_std])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots <a name=\"plots\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the font size for on the graphs\n",
    "font = {'size'   : 20}\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Visualizer class, which will start a series of prompts\n",
    "grapher = Visualizer(globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Visualizer method make_graphs can be called without arguments to create simple graphs without labels and with\n",
    "#  default size and colors, or with optional arguments defined (as below)\n",
    "# These arguments are for graphing ACTH & Cortisol against the mean data set\n",
    "#  from the Nelson TSST data\n",
    "grapher.make_graphs(xaxis_labels = ['Time (min)', 'Time (min)'],\n",
    "                    yaxis_labels = ['ACTH Concentration (pg/mL)', 'Cortisol Concentration (micrograms/dL)'],\n",
    "                    sims_line_labels = ['Simulated ACTH', 'Simulated Cortisol'],\n",
    "                    real_data_labels = ['Nelson ACTH - Patient Mean', 'Nelson Cortisol - Patient Mean'],\n",
    "                    legend_locs = ['upper right', 'upper right'],\n",
    "                    graph_titles = ['ACTH Concentration', 'Cortisol Concentration'],\n",
    "                    savefile=filename_root+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Optimization Run <a name=\"no-opt\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# run the solver with authors' published parameters\n",
    "data_no_opt = model(authors_params, y0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Optimizations for Multiple Patients <a name=\"runMultiple\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the patient number to start and end the optimization loop\n",
    "start_patient = 1\n",
    "end_patient = 10\n",
    "\n",
    "for patient in range(start_patient, end_patient+1):\n",
    "    print(f\"\\033[1mCurrent Patient: #{patient}\\033[0m\")\n",
    "    # Change the data set to cycle through patients in here. Will only work for Nelson TSST data, including subtype\n",
    "    #  data sets (as the basal data sets are only mean concentrations, not individual patients)\n",
    "    data_to_match = [nelson.ACTH[:,0], nelson.ACTH[:,patient+1], nelson.cortisol[:,0], nelson.cortisol[:,patient+1]]\n",
    "    y0 = [0, 0, 0, data_to_match[1][0], data_to_match[3][0]]\n",
    "    \n",
    "    opt_pars_tmp, simData_all_tmp = optimize.run(cost_fun, model, data_to_match, y0, bounds, num_iter=5)\n",
    "    \n",
    "    if patient == start_patient:\n",
    "        simData_all_multiple = simData_all_tmp\n",
    "        opt_pars_multiple = opt_pars_tmp\n",
    "    else:\n",
    "        simData_all_multiple = np.hstack((simData_all_multiple, simData_all_tmp))\n",
    "        opt_pars_multiple = np.hstack((opt_pars_multiple, opt_pars_tmp))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies <a name=\"dependencies\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
